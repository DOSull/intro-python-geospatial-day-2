{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e765af3",
   "metadata": {},
   "source": [
    "# Data wrangling in `pandas`\n",
    "It's rare that data are as you would like them to be, so a process of massaging and cleaning before analysis is almost always a necessary first step. \n",
    "\n",
    "Here we'll use data at Statistical Area 1 level for Wellington from the 2023 census. If you've worked with census data before, you'll know it has lots of quirks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f76581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sa1_data = pd.read_csv(\"2023_Census_totals_by_topic_for_individuals_by_SA1.csv\")\n",
    "sa1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687e027",
   "metadata": {},
   "source": [
    "**First quirk**: The natural index for these data is the SA1 code. So let's make it so. The column name is not very convenient, so we will rename it first, and also drop the `OBJECTID` column which is simply a sequence number of limited use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a3b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa1_data_v2 = sa1_data.drop(columns = \"OBJECTID\")\n",
    "sa1_data_v2 = sa1_data_v2.rename(\n",
    "    columns = {\"Statistical area 1 (SA1) 2023 code\": \"sa1_code\"})\n",
    "sa1_data_v2 = sa1_data_v2.set_index(\"sa1_code\")\n",
    "sa1_data_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae5128e",
   "metadata": {},
   "source": [
    "**Second quirk**: the `Landwater code` and `Landwater name` attributes are redundant. We probably don't need either of them, but before we drop them use the values to select only rows in the data that are 'Mainland':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66053556",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa1_data_v3 = sa1_data_v2[sa1_data_v2[\"Landwater name\"] == \"Mainland\"]\n",
    "cols_to_drop = [c for c in sa1_data_v3.columns if c.startswith(\"Landwater\")]\n",
    "sa1_data_v3 = sa1_data_v3.drop(columns = cols_to_drop)\n",
    "sa1_data_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e311a8c",
   "metadata": {},
   "source": [
    "**Quirk 3**: not really a quirk, but too much information! Say for present purposes we are really only interested in the 5-year age groups data and not the 500 or so other variables that have come with this dataset.\n",
    "\n",
    "Using the column name based indexing we just saw above, if we make up a list of only the columns that relate to this aspect of the data, then we can reduce things down further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_vars = []\n",
    "for c in sa1_data_v3.columns:\n",
    "    if \"Year: 2023\" in c and \"5-year groups\" in c:\n",
    "        age_vars.append(c)\n",
    "\n",
    "ages_data = sa1_data_v3[age_vars]\n",
    "ages_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f5d51",
   "metadata": {},
   "source": [
    "**Fourth quirk**: super-long column names. Theses are helpful in being highly specific, but also extremely inconvenient to work with. So let's write a simple function to rename them. There area a bunch of colons (`:`) and commas (`,`) in the variable names as they stand. It's convenient working in a notebook to do this in steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f281ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = ages_data.columns[0]\n",
    "varname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae80d9",
   "metadata": {},
   "source": [
    "It looks like splitting that on the colons and taking on the last section would be a start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname.split(\":\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1990409",
   "metadata": {},
   "source": [
    "OK... although notice that leading white space. Probably we only really need the `Age` and `0-4` part of this. Here's one approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname.split(\":\")[-1].strip().replace(\"(5-year groups - \", \"\").replace(\" years\", \"\").replace(\")\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379efe8c",
   "metadata": {},
   "source": [
    "That's close, but probably we don't want whitespace in our variable names (unlike the Census people, apparently...). It is also advisable to avoid hyphens which can be misinterpreted as minus signs in some settings, and lower case is probably preferable. So... a couple more steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname.split(\":\")[-1].strip().replace(\"(5-year groups - \", \"\").replace(\" years)\", \"\").replace(\" \", \"_\").replace(\"-\", \"_\").lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963ba03",
   "metadata": {},
   "source": [
    "That's more like it! Let's wrap all that up in a function, since we need to apply it to more than one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_age_var_name(varname):\n",
    "    remove = [\"(5-year groups - \", \" years\", \")\"]\n",
    "    replace = [\" \", \"-\"]\n",
    "    new_name = varname.split(\":\")[-1].lower().strip()\n",
    "    for r in remove:\n",
    "        new_name = new_name.replace(r, \"\")\n",
    "    for r in replace:\n",
    "        new_name = new_name.replace(r, \"_\")\n",
    "    return new_name.lower()\n",
    "\n",
    "clean_age_var_name(varname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef6e82",
   "metadata": {},
   "source": [
    "We can use this to make a 'renamer' dictionary which translates old names to new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "renamer = {}\n",
    "for old_name in ages_data.columns:\n",
    "    renamer[old_name] = clean_age_var_name(old_name)\n",
    "\n",
    "# recall that we could also do this as a one-liner comprehension\n",
    "# renamer = {n: clean_age_var_name(n) for n in ages_data.columns}\n",
    "\n",
    "renamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da415d",
   "metadata": {},
   "source": [
    "And apply it to the data frame using the `rename()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages_data_final = ages_data.rename(columns = renamer)\n",
    "ages_data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783090db",
   "metadata": {},
   "source": [
    "## Restricting the data to Wellington\n",
    "These data are for all of New Zealand, but we only want Wellington data. To narrow things down we use a table available from Statistics New Zealand at https://datafinder.stats.govt.nz/table/111243-geographic-areas-table-2023/ which shows the relationships between all the various spatial areas designated by Stats NZ made up from meshblocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2651f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_areas = pd.read_csv(\"geographic-areas-table-2023.csv\")\n",
    "stats_areas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19be9f3",
   "metadata": {},
   "source": [
    "And then use a columns selection to select only the ones we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa1_ur_lookup = stats_areas[[\"SA12023_code\", \"UR2023_name\"]]\n",
    "welly_sa1 = sa1_ur_lookup[sa1_ur_lookup.UR2023_name == \"Wellington\"]\n",
    "welly_sa1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25369a",
   "metadata": {},
   "source": [
    "There are some duplicates here because there are more meshblocks than there are SA1s. We also don't need the `UR2023_name` column any more, so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_sa1 = welly_sa1 \\\n",
    "    .drop(columns = [\"UR2023_name\"]) \\\n",
    "    .drop_duplicates()\n",
    "welly_sa1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b5dcd",
   "metadata": {},
   "source": [
    "If we now set the SA1 code variable to be the index of the `DataFrame` we get a 'bare` table ready to have data of interest joined to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_sa1 = welly_sa1.set_index(\"SA12023_code\")\n",
    "welly_sa1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfc50a",
   "metadata": {},
   "source": [
    "Finally, we can join the data for all of New Zealand (as we've seen above 32,601 rows) to the Wellington only SA1 codes (1408 rows). We will look at table joins in more detail later. The important thing here is that if you don't specify otherwise it joins based on the table indexes, which we've made sure are the same (at least they are if Stats NZ have done their job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_ages = welly_sa1.join(ages_data_final)\n",
    "welly_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cad49f3",
   "metadata": {},
   "source": [
    "With the exception of the specifics of the column renaming step, more or less all of the above are likely to be applicable as a first step in preparing data for analysis. Probably the most important decision above was choosing the index variable and assigning it with `set_index()`. In this case it's an obvious choice. The important thing is that is unique per record of interest (in this case the SA1s). Then dropping columns with either `drop(columns = ...)` or simply using the `df[[...]]` method to keep only columns you want. \n",
    "\n",
    "Renaming using a function and a 'renamer' dictionary as above seems like overkill, but is a useful approach to develop as it allows for the development of complex renaming schemes.\n",
    "\n",
    "Finally, I've mostly renamed the `DataFrame` at key steps along the way so that it's possible to double back a little bit and rerun a cell. In practical workflows you probably won't do that. It can be a useful technique when you are developing code, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8e48a",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "So we have the data we want... but it's got a bunch of weird values. What are `-999` people? These along with `-997`s are sentinel values Stats NZ use in census data tables to indicate 'Confidential' and 'Not available' respectively. We should consider ways to remove or replace these.\n",
    "\n",
    "In this case, the easiest method might be to use `.replace` and change all those values to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_ages.replace([-999, -997], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d3615",
   "metadata": {},
   "source": [
    "That works, but now we can't tell the difference between actual zeros and missing data. `pandas` has a special value `pd.NA` for this purpose, so can instead do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_ages_NA = welly_ages.replace([-999, -997], pd.NA)\n",
    "welly_ages_NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010305f9",
   "metadata": {},
   "source": [
    "This approach gives us options, the most useful being that we can easily tell `pandas` how to handle the NA values in calculations, or further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150ccc4",
   "metadata": {},
   "source": [
    "For example we can drop NA values, with options to remove any row (`axis=\"index\"`, the default), or any column (`axis=\"columns\"`) that has any NA value (`how=\"any\"` the default), or only any row or any column with all NA values (`how=\"all\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set axis to 'index' or 'columns' to drop either rows or columns\n",
    "# set how to 'any' to remove rows or columns with any NAs, and to 'all'\n",
    "# to remove only rows or columns that are all NAs\n",
    "welly_ages_NA.dropna(axis = \"index\", how = \"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40920540",
   "metadata": {},
   "source": [
    "You can also specify a `thresh=<some number>` to only remove rows/columns with at least that number of NAs. In this case that is useful, because we see from setting `axis = \"columns\", how = \"any\"` above that the total population column has no NAs, so it's easy to remove rows that are all NAs in all the other columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a256c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_ages_NA.dropna(axis = \"index\", thresh = 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19a9e1",
   "metadata": {},
   "source": [
    "### Handling NAs\n",
    "It's worth seeing how to include NA values in calculations. Most functions include a `skipna` parameter, which is set `True` by default. If we set it `False` then NA values will propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0364136",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_ages_NA.sum(skipna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53296747",
   "metadata": {},
   "source": [
    "Retaining NA values gives us more control and is worth doing until the point where it prevents analysis.\n",
    "\n",
    "## What about that total column\n",
    "Totals in census data are often not consistent with the contributing columns due to independent rounding of values and confidentiality suppression of some columns. We can check this by taking the difference. Note that we have to use `.iloc[]` here with two slices (rows and columns) to get row totals excluding the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_ages_NA.iloc[:, :-1].sum(axis = \"columns\") - welly_ages_NA.age_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b1f88",
   "metadata": {},
   "source": [
    "It probably makes sense to drop the total population column for further work (we can easily make a new one if we need it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f555eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_ages_final = welly_ages_NA.drop(columns = \"age_total\")\n",
    "welly_ages_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d3785",
   "metadata": {},
   "source": [
    "And since we've done a lot of work to get this far, let's save the result so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdd17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "welly_ages_final.to_csv(\n",
    "    \"welly-ages-final.csv\", index = True, index_label = \"sa1_code\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-python-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
